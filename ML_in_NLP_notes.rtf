{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;\red51\green51\blue51;
}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;\cssrgb\c26275\c26275\c26275;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf0 \cb2 \expnd0\expndtw0\kerning0
BUILDING TRANSFORMER-BASED NLP APPLICATIONS\
\
\
To join the course platform (available until 6 months after the course on 21 March 2022):\cb1 \
\cb2 1: Log in at https://courses.nvidia.com/join\cb1 \
\cb2 2: Navigate to https://courses.nvidia.com/dli-event\cb1 \
\cb2 3: Enter event code  GTC21M_NLP_BH89 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2 \ul \ulc0 \
Progress\
\pard\pardeftab720\partightenfactor0
\cf0 \ulnone > Lab 1\
>> 000 DONE (just run it)\
>> 010 DONE (just run it)\
>> 020 almost DONE reading! (see \'93lab_1_020.png\'94)\
>> 030 NOT done\
> Lab 2\
>> 000 NOT done\
>> 010 NOT done\
>> 020 NOT done\
>> 030 NOT done\
> Lab 3\
>> 000 DONE\
>> 010 DONE\
>> 020 DONE\
>> 030 DONE\
>> 040 DONE\ul \
\
\ulnone # Get certificate:\
> Go to https://courses.nvidia.com/courses/course-v1:DLI+C-FX-03+V3/course\
> Assessment Coding Project\
> Click \'93LAUNCH\'94 => code the coding project in a new tab\
> Come back to the tab in which start was clicked => click \'93ASSESS TASK\'94\
\pard\pardeftab720\partightenfactor0
\cf0 \ul \
\pard\pardeftab720\partightenfactor0
\cf4 \ulnone You\'a0have\'a0to\'a0create\'a0an\'a0account\'a0{\field{\*\fldinst{HYPERLINK "https://courses.nvidia.com/dli-event/"}}{\fldrslt \cf0 https://courses.nvidia.com/dli-event/}}\cf0 \ul \
\pard\pardeftab720\partightenfactor0
\cf0 \ulnone \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://courses.nvidia.com/dli-event/"}}{\fldrslt \cf0 https://courses.nvidia.com/dli-event/}}\
\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=U9Zh57dGsH4"}}{\fldrslt \cf0 https://www.youtube.com/watch?v=U9Zh57dGsH4}}\ul \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/"}}{\fldrslt \cf0 \ulnone https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/}}\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=ghEmQSxT6tw"}}{\fldrslt \cf0 https://www.youtube.com/watch?v=ghEmQSxT6tw}}\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/"}}{\fldrslt \cf4 \ulnone https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/}}\cf4 \ulnone \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://link.springer.com/article/10.1007/s11042-020-10183-2"}}{\fldrslt \cf0 https://link.springer.com/article/10.1007/s11042-020-10183-2}}\
\pard\pardeftab720\partightenfactor0
\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://catalog.ngc.nvidia.com/orgs/nvidia/teams/dli/containers/dli-nlp-nemo"}}{\fldrslt \cf0 \cb2 https://catalog.ngc.nvidia.com/orgs/nvidia/teams/dli/containers/dli-nlp-nemo}}\cf0 \cb2 \
\pard\pardeftab720\partightenfactor0
\cf0 \ul \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/NVIDIA/Megatron-LM"}}{\fldrslt \cf0 \ulnone https://github.com/NVIDIA/Megatron-LM}}\ulnone \
\
}